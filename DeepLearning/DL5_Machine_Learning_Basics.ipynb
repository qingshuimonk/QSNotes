{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some most common machine learning tasks:\n",
    "- Classification\n",
    "- Classification with missing inputs\n",
    "- Regression\n",
    "- Transcription: unstructured data -> discrete, textual form\n",
    "- Machine translation\n",
    "- Structured output: e.g. parsing\n",
    "- Anomaly detection\n",
    "- Synthesis and sampling\n",
    "- Imputation of missing values\n",
    "- Denoising\n",
    "- Density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: use input $x\\in \\mathbb{R}^n$ to predict output $y\\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat y=w^Tx+b, \\ w\\in\\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error**: $MSE_{test}=\\frac{1}{m}\\sum_i(\\hat{y}^{(test)}-y^{(test)})_i^2=\\frac{1}{m}||\\hat{y}^{(test)}-y^{(test)}||_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla_wMSE_{train}=0$  \n",
    "$\\Rightarrow\\nabla_w\\frac{1}{m}||\\hat{y}^{(train)-y^{(train)}}||_2^2=0$  \n",
    "$\\Rightarrow\\frac{1}{m}\\nabla_w||X^{(train)}w-y^{(train)}||_2^2$  \n",
    "$\\Rightarrow\\nabla_w(X^{(train)}w-y^{(train)})^T(X^{(train)}w-y^{(train)})$  \n",
    "$\\Rightarrow\\nabla_w(w^TX^{(train)}w-2w^TX^{(train)T}y^{(train)}+y^{(train)T}y^{(train)})$  \n",
    "$\\Rightarrow2X^{(train)T}X^{(train)}w-2X^{(train)T}y^{(train)}=0$  \n",
    "$\\Rightarrow w=(X^{(train)T}X^{(train)})^{-1}(X^{(train)T}y^{(train)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity, Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to perform well on previously unobserved inputs is called **generalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capacity**: a model's ability to fit a wide variety of functions <- controlled by **bypothesis space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Occam's Razor**: among competing hypotheses that explain known observations equally well, one should choose the \"simplest\" one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vapnik-Chervonenkis (VC) Dimension**: the largest possible value of m for which there exists a training set of $m$ different $\\mathbf{x}$ points that the classifier can label arbitrarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight Decay (regularization parameter)**: $J(w)=MSE_{train}+\\lambda w^Tw$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{ML}=argmax_\\theta p_{model}(\\mathbb{X};\\theta)=argmax_\\theta\\prod_{i=1}p_{model}(x^{(i=1)};\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a logarithm to make it into sum: $\\theta_{ML}=argmax_\\theta\\sum_{i=1}^mlogp_{model}(x^{(i)};\\theta)$  \n",
    "$\\Rightarrow\\theta_{ML}=argmax_\\theta\\mathbb{E}_{x\\sim\\hat{p}_{data}}logp_{model}(x;\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bhplayground]",
   "language": "python",
   "name": "conda-env-bhplayground-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
