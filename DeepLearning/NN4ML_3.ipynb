{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Machine Learning (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Weights of a Linear Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working procedure of perceptron cannot working on complex situation\n",
    "- it assumes that the sum of two \"good\" solutions is still a \"good\" solution\n",
    "- NN can work on non-convex solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Neurons:\n",
    "- real valued output: $y=\\sum_iw_ix_i=\\mathbf{w}^T\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative approach:\n",
    "- start with random gess\n",
    "- adjust them to get a better fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"delta-rule\" for learning: $\\delta w_i=\\epsilon x_i(t-y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define error:  \n",
    "$E=\\frac{1}{2}\\sum_{n\\in training}(t^n-y^n)^2$\n",
    "2. Derivative for the weights:  \n",
    "$\\frac{\\partial{E}}{\\partial{w_i}}=\\frac{1}{2}\\sum_n\\frac{dE^n}{dy^n}\\frac{\\partial{y^n}}{\\partial{w_i}}=-\\sum_nx_i^2(t^n-y^n)$\n",
    "3. Batch weight updates:  \n",
    "$\\delta w_i=-\\epsilon\\frac{\\partial{E}}{\\partial{w_i}}=\\sum_n\\epsilon x_i^n(t^n-y^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike perceptron, we update weight by input vector scaled with residual error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Error Surface for Linear Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch learning: travels perpendicular to contour lines  \n",
    "Online learning: zig-zag towards center  \n",
    "The learning can be slow when ellipse is very elongated (the gradient will be almost perpendicular to direction towards minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Weights of a Logistic Output Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic neuron:  \n",
    "$z=b+\\sum_ix_iw_i$  \n",
    "$y=\\frac{1}{1+e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function have nice derivative makes learning easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of z:  \n",
    "$\\frac{\\partial{z}}{\\partial{w_i}}=x_i$, $\\frac{\\partial{z}}{\\partial{x_i}}=w_i$  \n",
    "$\\frac{dy}{dz}=y(1-y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the chain rule:  \n",
    "$\\frac{\\partial{y}}{\\partial{w_i}}=\\frac{dy}{dz}\\frac{\\partial{z}}{\\partial{w_i}}=y(1-y)x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial{E}}{\\partial{w_i}}=\\sum_n\\frac{dE}{dy}\\frac{\\partial{y^n}}{\\partial{w_i}}=\\sum_ny^n(1-y^n)x_i^n(t^n-y^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has an extra $y^n(1-y^n)$ term compared with delta-rule (which is $\\frac{\\partial{E}}{\\partial{w_i}}=-\\sum_nx_i^2(t^n-y^n)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use error derivatives with respect to hidden activities -> compute how fast the error changes when changing hidden activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pics/3-4-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pics/3-4-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Derivatives Computed by Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimization issue: individual case -> good set of weights\n",
    "- Generalization issue: learned weights -> not seen cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization:\n",
    "- How often to update:\n",
    "  - Online (Zig-zag)\n",
    "  - Full batch (large number)\n",
    "  - Mini batch (random subset of full batch)\n",
    "- How much to update:\n",
    "  - Learn rate fixed\n",
    "  - Adapt learning rate\n",
    "  - Adapt learning rate on each connection\n",
    "  - Don't use the steepest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting: Complex model is easy to overfit\n",
    "- Unreliable target value\n",
    "- Sampling error\n",
    "To preven overfitting:\n",
    "- weight decay\n",
    "- weight sharing\n",
    "- early stopping\n",
    "- model averaging\n",
    "- Bayesian fitting of neural nets\n",
    "- Droupout\n",
    "- Generative pre-training"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bhplayground]",
   "language": "python",
   "name": "conda-env-bhplayground-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
